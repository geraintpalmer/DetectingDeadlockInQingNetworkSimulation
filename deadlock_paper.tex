\documentclass{article}

\usepackage{fullpage}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc}
\usepackage{standalone}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage[ruled]{algorithm2e}
\usepackage{adjustbox}
\usepackage{enumerate}
\usepackage[nocompress]{cite}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}

\title{On Deadlocking in Queueing Networks}
\author{Geraint Ian Palmer, Paul Harper, Vincent Knight}
\date{\today}


\begin{document}
\onehalfspacing

\maketitle

\begin{abstract}
In this paper a deadlock in open restricted queueing networks is investigated.
A method to detect when deadlock occurs in simulations of these networks in presented, using a state digraph.
Markov models of five deadlocking queueing networks are given, and their properties on expected time to deadlock explored.
These networks are a one node single server, one node multi server, two node single server without loops, two node multi server without loops, and two node single server with loops.
These properties are compared to results obtained using the simulation model.
Finally a bound on the time to deadlock of the two node single server with loops network is derived.
\end{abstract}

\section{Introduction}

Restricted open queueing networks that can experience deadlock are under-discussed in the literature.
This paper addresses this by investigating deadlock properties in these queueing networks.
A method of detecting deadlock in discrete event simulations of queueing networks is presented, and markovian models of five open restricted queueing networks are analysed, and the properties of their time to deadlock investigated.
Finally a bound on the time to deadlock is given for one of these queueing networks.

Central to the study of deadlock in restricted queueing networks is the concept of blocking.
Given two queues in tandem such that customers leaving the first service station enter the second, and the second queue has limited queueing capacity.
If the second queue is full, and a customer finishes service at the first queue, that customer cannot join the next queue due to lack of capacity. This customer remains with the server, blocking other customers from beginning service with that server, until space becomes available at the second queue.
This is referred to as blocking.

Throughout this paper service centers will be referred to as nodes, and an open unrestricted queueing network will use the following notation for the $i$th node:

\begin{itemize}
	\item $\Lambda_i$ denotes the external arrival rate.
	\item $\mu_i$ denotes the service rate.
	\item $c_i$ denotes the number of parallel servers.
	\item $n_i$ denotes the queueing capacity.
	\item $r_{ij}$ denotes the routing probability from node $i$ to node $j$ upon completion of service at node $i$.
\end{itemize}

Exponential service times and Poisson arrivals are assumed.

For the purposes of this paper, deadlock is defined as follows.\\

\begin{definition}
    When a simulation is in a situation where at least one service station,
    despite having arrivals, ceases to begin or finish any more services
    due to recursive upstream blocking, the system is said to be in deadlock.
\end{definition}

Figure~\ref{fig:firstexample} shows a three node queueing network in a deadlocked state.
The customers occupying servers $B_1$ and $B_2$ are blocked from entering the top node, while the customer occupying server $A_1$ is blocked from entering the middle node.
Due to mutual blocking, these customers are preventing any more natural movement in these two nodes.
Note however that on part of the network need be in deadlock, as the bottom node is free to continue services as normal.

\begin{figure}[!htbp]
  \begin{center}
  \includestandalone[width=0.5\textwidth]{images/transientdeadlock}
  \caption{A three node queueing network in deadlock.}
  \label{fig:firstexample}
  \end{center}
\end{figure}

This paper is structured as follows: Section~\ref{sec:litreview} discusses the exsisting literature on deadlock and deadlock strategies. Section~\ref{sec:detectingdeadlock} presents a method of detecting deadlock in discrete event simulations of queueing networks. Section~\ref{sec:simulation} briefly describes the discrete event simulation model used to obtain the results in this paper. Section~\ref{sec:markovmodels} presents Markov models of five deadlocking queueing networks, derives expected time to deadlock, and compares with resutls obtain through the simulation model. Finally Section~\ref{sec:bound} derives a bound for the expected time to deadlock for one of the queueing networks discussed.





\section{Literature Review}\label{sec:litreview}


Restricted queueing networks that exhibit blocking are well discussed in the literature \cite{hunt56, baber08, aviitzhakyadin65, takahashi80, koizumietal05, latoucheneuts80, korporaaletal00}. Discussion on restricted queueing networks with feedback loops, that may exhibit deadlock, are sparse however.

General deadlock situations that are not specific to queueing networks are discussed in \cite{coffmanelphick71}.
Conditions for this type of deadlock, also referred to as deadly embraces, to potentially occur are given:
\begin{itemize}
  \item Mutual exclusion: Tasks have exclusive control over resources.
  \item Wait for: Tasks do not release resources while waiting for other resources.
  \item No preemption: Resources cannot be removed until they have been used to completion.
  \item Circular wait: A circular chain of tasks exists, where each task requests a resource from another task in the chain.
\end{itemize}

In open restricted queueing networks the mutual exclusion condition is satisfied as customers cannot share servers; the wait for condition is satisfied due to the blocking rules defined previously; the no preemption condition is satified in networks that have no or non-preemptive priority (this report will only look at networks with no priority); and the circular wait condition is satisfied if the queueing network contains a cycle where all nodes have limited queueing capacity, that is feedback loops.

In general there are three strategies for dealing with deadlock \cite{kawadkaretal14, elmagarmid86}:

\begin{itemize}
  \item Prevention, in which the system cannot possibly deadlock in the first place.
  \item Avoidance, in which decisions are made as time unfolds to avoid reaching deadlock.
  \item Detection and recovery.
\end{itemize}

\subsection{Deadlock Prevention}

Deadlock prevention has been discussed in queueing networks.
For closed networks of $K$ customers with only one class of customer, \cite{kunduakyildiz89} proves the following condition to ensures no deadlock: for each minimum cycle $C$, $K < \sum_{j\in C} B_j$, the total number of customers cannot exceed the total queueing capacity of each minimum subcycle of the network.
The paper also presents algorithms for finding the minimum queueing space required to ensure deadlock never occurs, for closed cactus networks, where no two cycles have more than one node in common.
This result is extended to multiple classes of customer in \cite{liebeherrakyildiz95}, with more restrictions such as single servers and each class having the same service time distribution.
Here a integer linear program is formulated to find the minimum queueing space assignment that prevents deadlock.
The literature does not discuss deadlock properties in open restricted queueing networks.

\subsection{Deadlock Avoidance}

There are algorithms discussed in the literature for the dynamic avoidance of deadlock.
In the Banker's Algorithm \cite{dijkstra82, kawadkaretal14}, unsafe states, those that will lead to deadlock, are avoided by ensuring actions leading to these states are not carried out.

\subsection{Deadlock Detection \& Recovery}

General deadlock detection in systems unspecific to queueing networks are discussed in \cite{coffmanelphick71}.
A popular method of detecting general deadlock is the use of wait-for graphs, state-graphs and their variants \cite{cheng90, elmagarmid86, coffmanelphick71, choetal95}.
These wait-for graphs, keep track of all circular wait relations between tasks.

In \cite{coffmanelphick71} dynamic state-graphs are defined with resources as vertices and requests as edges.
For scenarios where there is only one type of each resource, deadlock arises if and only if the state-graph contains a cylce.
In \cite{choetal95} the vertices and edges of the state graph are given labels in relation to a reference node.
Using these labels \textit{simple bounded circuits} are defined whose existence within the state graph is sufficient to detect deadlock.





\section{Detecting Deadlock}\label{sec:detectingdeadlock}

In order to detect when deadlock has occured in a queueing network simulation, the state digraph is used, defined below.\\

\begin{definition}
The state digraph $D(t)$ of a queueing network defines that network's state at any time $t$.
Vertices of the state digraph correspond to servers of the network.
A directed edge denotes a blockage relationship in the following manner: if a customer at the $k$th server of node $i$ is blocked from entering node $j$, then there are directed edges from the vertex corresponding to node $i$'s $k$th server to every vertex corresponding to the servers of node $j$.
\end{definition}

To illustrate this concept Figure~\ref{fig:exampledigraph_deadlock} and Figure~\ref{fig:exampledigraph_nodeadlock} show a three node network in and out of deadlock, and the corresponding state digraph in each case.


\begin{figure}[!htbp]
\begin{subfigure}[b]{0.9\textwidth}
  \begin{center}
  \includestandalone[width=0.6\textwidth]{images/exampledigraph_in}
  \end{center}
  \caption{A three node queueing network in deadlock, with state digraph.}
  \label{fig:exampledigraph_deadlock}
\end{subfigure}
\begin{subfigure}[b]{0.9\textwidth}
  \begin{center}
  \includestandalone[width=0.6\textwidth]{images/exampledigraph_out}
  \end{center}
  \caption{A three node queueing network not in deadlock, with state digraph.}
  \label{fig:exampledigraph_nodeadlock}
\end{subfigure}
\caption{Example of the state digraph.}
\label{fig:exampledigraph}
\end{figure}

Consider one weakly connected component $G(t)$ of $D(t)$. Consider the node $X_a \in G(t)$. Some observations:

\begin{itemize}

  \item Consider the node $X_a \in G(t)$. If $X_a$ is unoccupied, then $X_a$ has no incident edges.
  \item Consider the case when $X_a$ is occupied by individual $a$, whose next destination is node $j$. Then $X_a$'s direct successors are the servers occupied by individuals who are blocked or in service at node $j$.
  \item It can interpreted that all $X_a$'s descendants are the servers whose occupants are directly or indirectly blocking $a$, and interpret all $X_a$'s ancestors as those servers whose individuals who are being blocked directly or indirectly by $a$.
  \item Note that the only possibilities for $\text{deg}^{\text{out}}(X_a)$ are 0 or $c_j$. If $\text{deg}^{\text{out}}(X_a) = c_j$ then $a$ is blocked by all its direct successors. The only other situation is that $a$ is not blocked, and $X_a \in G(t)$ because $a$ is in service at $X_a$ and blocking other individuals, in which case $\text{deg}^{\text{out}}(X_a) = 0$.
  \item It is clear that if all of $X_a$'s descendants are occupied by blocked individuals, then the system is deadlocked at time $t$.
  \item By definition all of $X_a$'s ancestors are occupied by blocked individuals.

\end{itemize}

The following results detect deadlock for open restricted queueing networks.

\begin{theorem}
A deadlocked state arises at time $t$ if and only if $D(t)$ contains a knot.
\end{theorem}

\begin{proof}
Consider one weakly connected component $G(t)$ of $D(t)$ at time $t$.
All vertices of $G(t)$ are either descendants of another vertex and so are occupied by an individual who is blocking someone; or are ancestors of another vertex, and so are occupied by someone who is blocked.

Assume that $G(t)$ contains a vertex $X$ such that $\text{deg}^{\text{out}}(X) = 0$, and there is a path from every other non-sink vertex to $X$.
This implies that $X$'s occupant is not blocked and is a descendant of another vertex.
Therefore $Q$ is not deadlocked as there does not exist a vertex whose descendants are all blocked.

Now assume that we have deadlock.
For a vertex $X$ who is deadlocked, all descendants of $X$ are are occupied by individuals who are blocked, and so must have out-degrees greater than 0.
And so there is no path from $X$ to a vertex with out-degree of 0.

\end{proof}


\begin{proposition}
For queueing networks:
\begin{itemize}
  \item with one node
  \item with two nodes, each with two or fewer parallel servers
  \item with a finite amount of nodes, each with a single server
\end{itemize}
a deadlocked state arises if and only if there exists a weakly connected component without a sink node.
\end{proposition}

\begin{proof}
Consider a one node queueing network.

If there is deadlock, then all servers are occupied by blocked individuals, and so all servers have an out-edge.

Consider a two node queueing network, each node with 2 or fewer parallel servers.

If both nodes are involved in the deadlock, so there is a customer in node 1 blocked from entering node 2, and a customer from node 2 blocked from entering node 1, then all servers in node 1 and node 2 in $D(t)$ will have out edges as they are occupied by a blocked individual.
The servers of node 1 and 2 consist of the entirety of $D(t)$, and so there is no sink nodes.

Now consider the case when only one node is involved in the deadlock.
Without loss of generality, let's say that node 1 is in deadlock with itself, then the servers of node 1 have out-edges.
For the servers of node 2 to be part of that weakly connected component, there either needs to be an edge from a server in node 1 to a server in node 2, or and edge from a server in node 2 to a server in node 1.
An edge from a server in node 1 to a server in node 2 implies that a customer from node 1 is blocked from entering node 2, and so node 1 is not in deadlock with itself.
An edge from a server in node 2 to a server in node 1 implies that a customer in node 2 is blocked from entering node 1.
In this case one server in node 2 has an out-edge.
Now either the other server of node two is still in server, and so isn't part of that weakly connected component, or the other server's customer is blocked and so has an out edge.

For the case of a queueing network with two nodes and more than 2 servers at node 2, consider the following counter-example:

Node $A$ has two parallel server, node $B$ has three parallel sevrers.
Begin with all servers occupied by customers in service and full queues.
The customer at server $A_1$ is blocked to node $A$.
The customer at server $B_1$ is blocked to node $A$.
The customer at server $B_2$ is blocked to node $B$.
The customer at server $A_2$ is blockec to node $A$.
The resulting state digraph in Figure~\ref{fig:counter_example_1} has a weakly connected component with a sink.

Consider a queueing network with $N$ nodes, each with a single server.

If $1 \leq n \leq N$ nodes are involved in the deadlock, then each server in those $n$ nodes has a blocked customer, and so has an out-edge.
Of the other nodes, they can only be in the same weakly connected component if either they contain a indiviual blocked by those in deadlock, in which case they will have an out edge; or they contain a blocked individual blocked by those directly or indirectly blocked by those in deadlock, in which case they will have an out edge; or they are blocking someone who is blocked directly or indirectly by those in deadlock.
However this last case cannot happen, as every node is single server each person can only be blocked by one other individual at a time.

For the case of a queueing network with more than two nodes with multiple servers, the following counter-example proves the claim:

Node $A$ has one parallel server, node $B$ has two parallel servers, and node $C$ has three parallel servers.
Begin with all servers occupied by customers in service and full queues.
The customer at server $B_1$ is blocked from entering node $A$.
Then the customer at server $C_1$ is blocked from entering node $B$.
Then the customer at server $A_1$ is blocked from entering node $A$.
The resulting state digraph in Figure~\ref{fig:counter_example_2} has a weakly connected component with a sink.

\end{proof}

\begin{figure}
\begin{subfigure}{0.5\textwidth}
\begin{center}
\includestandalone[width=0.8\textwidth]{images/counter_example_digraph_1}
\end{center}
\caption{State Digraph of Counter-Example 1.}
\label{fig:counter_example_1}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
\begin{center}
\includestandalone[width=0.65\textwidth]{images/counter_example_digraph_2}
\end{center}
\caption{State Digraph of Counter-Example 2.}
\label{fig:counter_example_2}
\end{subfigure}
\end{figure}


\section{Simulation Model}\label{sec:simulation}

\section{Markovian Models of Deadlocking Queueing Networks}\label{sec:markovmodels}

\subsection{One Node}

\subsection{Two Node without Self-Loops}

\subsection{Two Node with Self-Loops}

\subsection{One Node Multi-Server}

\subsection{Two Node Multi-Server without Self-Loops}

\section{A Bound on the Time to Deadlock}\label{sec:bound}

\bibliographystyle{plain}
\bibliography{refs}
\end{document}