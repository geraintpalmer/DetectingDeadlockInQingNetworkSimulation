\documentclass{article}

\usepackage{fullpage}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc}
\usepackage{standalone}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage[ruled]{algorithm2e}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\title{Deadlocking in Queueing Networks}
\author{Geraint Palmer}
\date{}

\begin{document}
\onehalfspacing

\maketitle

This section will define and discuss the properties and detection of deadlock in queueing networks.
Throughout the section, when discussing queueing networks, it is assumed that
the queueing network is open and connected.
Open queueing networks are those networks that have at least one node to which customers arrive from the exterior, and and least one node from which customers leave to the exterior.

\section{Introduction}

The simplest representation of deadlock is shown in Figure~\ref{fig:gridlock}.
Here deadlock, or gridlock, is caused by the mutual blocking of cars.
The blue cars are blocked from movement due to the yellow cars; the yellow cars are blocked from movement due to the green cars, the green cars are blocked from movement due to the red cars; and the red cars are blocked from movement due to the blue cars.
This can be interperated as the blue cars indirectly blocking themselves.

\begin{figure}[H]
  \begin{center}
  \includestandalone[width=0.5\textwidth]{images/gridlock}
  \caption{Gridlock, a representation of general deadlock.}
  \label{fig:gridlock}
  \end{center}
\end{figure}

This work will investigate deadlocking in queueing networks.
The following definition will be used.

\begin{definition}
    When a simulation is in a situation where at least one service station,
    despite having arrivals, ceases to begin or finish any more services
    due to recursive upstream blocking the system is said to be in deadlock.
\end{definition}

Deadlock can be experienced in any open queueing network that experiences
blocking, with at least once cycle containing all service stations with
resticted queueing capacity.

Deadlock occurs when a customer finishes service at node $i$ and is blocked from transitioning to node $j$; however the individuals in node $j$ are all blocked, directly or indirectly, by the blocked individual in node $i$.
That is, deadlock occurs if every individual blocking individual $X$, directly or indirectly, are also blocked.

In Figure~\ref{fig:2in_deadlock} a simple two node queueing network is shown in a deadlocked state.
Customer occupying server $A_1$ has finished service at node $A$, but remains there as there is not
enough queueing space at node $B$ to accept them.
We say the customer at server $A_1$ is blocked by the customer at server $B_1$, as he is waiting for that customer to be released.
Similarly, the customer occupying server $B_1$ has finished service at node $B$, but remains there as there is not enough queueing space at node $A$, and so the customer at server $B_1$ is blocked by the customer at server $A_1$.

When there are multiple servers, individuals become blocked by all customers in
service at the destination service station.
Figure~\ref{fig:inout_deadlock_in} shows two nodes in deadlock, the customer occupying server $A_1$ is blocked by customers at both $B_1$ and $B_2$, who are both blocked by the customer at $A_1$.
However in \ref{fig:inout_deadlock_out}, customer at $A_1$ is blocked by customers at both $B_1$ and $B_2$, but the customer at $B_2$ isn't blocked, and so there is no deadlock.

\begin{figure}[H]
  \begin{center}
  \includestandalone[width=0.5\textwidth]{images/2nodesindeadlock}
  \caption{Two nodes in deadlock.}
  \label{fig:2in_deadlock}
  \end{center}
\end{figure}

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includestandalone[width=0.9\textwidth]{images/2nodesindeadlockmulti}
  \caption{Two nodes in deadlock.}
  \label{fig:inout_deadlock_in}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includestandalone[width=0.9\textwidth]{images/2nodesnotdeadlocked}
  \caption{Two nodes not deadlocked}
  \label{fig:inout_deadlock_out}
\end{subfigure}
\caption{Two nodes: a) in deadlock and b) not in deadlock.}
\label{fig:inout_deadlock}
\end{figure}

Note that the whole queueing network need not be deadlocked, only a part of it.
If one section of the network is in deadlock, then the system is deadlocked, even though customers may still be able to have services and transitions in other areas of the network.
An example is shown in Figure~\ref{fig:trans}.
This idea is expanded on in Section~\ref{sec:typesofdeadlock}.

\section{Literature Review}

Restricted queueing networks, or queueing networks with no or limited intermediate queues between service stations are more complicted to analyse.
In these systems, if a customer finishes service at one node but is unable to join a queue at his destination node due to lack of queueing space, that customer remains in the current node, restricting his servers from starting the next customer's service.
This is known as blocking.
Since blocking introduces interdependencies between nodes, the product form solution of unrestricted networks is not appropriate.
One of the first papers to consider these sorts of systems was \cite{hunt56}.
Results are derived by writing out and solving the systems' difference equations.
The same method is used in \cite{baber08}.
The thesis investigates two and three node systems, as well as systems with one service sentre with infinite queue routing into a number of these two and three node systems.

A two node system with no intermediate queue and blocking is studied in \cite{aviitzhakyadin65}. In this paper the moment generating functions of waiting time and number of customers in the system are derived, from which further performance measures can be obtained.

Two features of blocking are described in \cite{koizumietal05}: $(i)$ patients completing service at a blocked station remain there until there is sufficient queueing space at the next station, and $(ii)$ these patients block other patients from entering that station.
If a station only has characteristic (i) then it is referred to as `classic congestion', and if a station has both characteristics it is referred to as `blocking'.
Three blocking situations are studied in \cite{latoucheneuts80}, defined by rules on the system reaching `full blocking' and their `unblocking rule'.
If the node that is subject to blocking has $r$ parallel servers, then once $r^*$ ($1\leq r\leq r^*$) servers become blocked all remaining unblocked servers stop service and the node becomes fully blocked.
Given that there is a room for $M$ customers to wait between nodes, once there are only $k^*$ ($0\leq k^*\leq M+r^*-2$) customers waiting between the nodes all services may start again and the node becomes unblocked.

And approximation method for solving queueing networks with downstream blocking only in presented in \cite{takahashi80}.
The algorithm finds the mean values of a queueing network with feedforward flows and single server nodes.
Iteratively working from the node furthest downstream and working backwards, if that station does exhibit blocking it finds the \textit{effective service time}, that is the weighted sum of service time and the mean time blocked and waiting to transition to the next node, and computes the effective service time for the next upstream node with a recursive formula.
This method is adapted to multi-server queues in \cite{koizumietal05}, and a similar iterative method was used in \cite{korporaaletal00}.

Restriced queueing networks can give rise to the phenomenon of deadlock.
This can cause problems for both analytical and simuation models, and most of the literature on blocking either does not consider networks with feedback loops, ignores the possibility of deadlock, or conveniently assumes the networks are
deadlock-free.

General deadlock situations that are not specific to queueing networks are discussed in \cite{coffmanelphick71}.
Conditions for this type of deadlock, also referred to as deadly embraces, to potentially occur are given:
\begin{itemize}
  \item Mutual exclusion: Tasks have exclusive control over resources.
  \item Wait for: Tasks do not release resources while waiting for other resources.
  \item No preemption: Resources cannot be removed until they have been used to completion.
  \item Circular wait: A circular chain of tasks exists, where each task requests a resource from another task in the chain.
\end{itemize}

In \cite{kawadkaretal14} it is noted that in general there are three strategies for dealing with deadlock:

\begin{itemize}
  \item Prevention, in which the system cannot possibly deadlock in the first place.
  \item Dynamic avoidance, in which decisions are made as time unfolds to avoid reaching deadlock.
  \item Detection and recovery.
\end{itemize}

Deadlock prevention has been discussed in queueing networks.
For closed networks of $K$ customers with only one class of customer, \cite{kunduakyildiz89} proves the following condition to ensures no deadlock: for each minimum cycle $C$, $K < \sum_{j\in C} B_j$, the total number of customers cannot exceed the total queueing capacity of each minimum subcycle of the network.
The paper also presents algorithms for finding the minimum queueing space required to ensure deadlock never occurs, for closed cactus networks, where no two cycles have more than one node in common.
This result is extended to multiple classes of customer in \cite{liebeherrakyildiz95}, with more restrictions such as single servers and each class having the same service time distribution.
Here a integer linear program is formulated to find the minimum queueing space assignment that prevents deadlock.
The literature does not discuss deadlock properties in open restricted queueing networks.

There are algorithms discussed in the literature for the dynamic avoidance of deadlock.
In the Banker's Algorithm \cite{dijkstra82, kawadkaretal14}, unsafe states, those that will lead to deadlock, are avoided by ensuring actions leading to these states are not carried out.

General deadlock detection in systems unspecific to queueing networks are discussed in \cite{coffmanelphick71}.
Here dynamic state-graphs are defined, with resources as vertices and requests as edges.
For scenarios where there is only one type of each resource, deadlock arises if and only if the state-graph contains a cylce.

In \cite{choetal95} the vertices and edges of the state graph are given labels in relation to a reference node.
Using these labels \textit{simple bounded circuits} are defined whose existance within the state graph is sufficient to detect deadlock.


\section{Types of Deadlock}\label{sec:typesofdeadlock}
In the introduction an idea was introduced that parts of a queueing network can be in a deadlocked state, although other parts will continue to flow.
The different configurations of which nodes experience deadlock can be thought
of as different types of deadlock.
The amount of different types of deadlock that a queueing network can experience
is equal to the number of directed cycles in in the queueing network's routing
matrix. % This paragraph will change and will need more discussion of last
%sentence (images etc...)

For connected queueing networks, these deadlocks can be classified into transient deadlocked states and the absorbing deadlocked state.\\


\begin{definition}
    A transient deadlock state is when there are still some changes of state
    whilst a subgraph of the queueing network is itself in deadlock.\\
\end{definition}

\begin{definition}
    The absorbing deadlock state is when all subgraphs of the
    queueing network are in deadlock.\\
\end{definition}

Figure~\ref{fig:transabsorb} shows a three nodes network in a transient deadlocked state, and an absorbing deadlocked state.
In Figure~\ref{fig:trans} the occupants of servers $B_1$ and $B_2$ are blocked from entering node $A$; and the occipant of server $A_1$ is blocked from entering node $B$, and so these two nodes are in deadlock.
However, node $C$ can continue with regular services, until the occupants of every server of $C$ attempt to join a deadlocked node.
At which point, the whole system is deadlocked, and so has reached absorbing deadlock, show in Figure~\ref{fig:absorb}.

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includestandalone[width=0.9\textwidth]{images/transientdeadlock}
  \caption{Transient deadlock.}
  \label{fig:trans}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includestandalone[width=0.9\textwidth]{images/absorbingdeadlock}
  \caption{Absorbing deadlock.}
  \label{fig:absorb}
\end{subfigure}
\caption{Types of deadlock: a) transient and b) absorbing.}
\label{fig:transabsorb}
\end{figure}

It should be clear that if the queueing network is connected, then there is a non-zero probability that once one part of the network is in deadlock, the whole system will fall into a deadlocked state, simply by the individuals in the non-deadlocked nodes attempting to transition into a deadlocked node.
That is, once $Q$ falls into one of the transient deadlocked states, it will eventually transition, either directly or through other transient deadlocked states, into the absorbing deadlocked state.

If the routing matrix of $Q$ is complete, that is there is a possible route from every service station to every other service station, then there are $\sum_{i=1}^N \binom{N}{i}$ possible deadlock types.


\section{Dynamically Detecting Deadlock}
In the following subsections, a method will be presented to dynamically detect deadlock in discrete event simulations of queueing networks.
The following definitions will be required in this section:

\begin{tabular}{ p{5cm} p{10cm} }
  $\left| V(D) \right|$        & The order of the directed graph $D$ is its number of vertices. \\
  Weakly connected component   & A weakly connected component of a digraph containing $X$ is the set of all nodes that can be reached from $X$ if we ignore the direction of the edges. \\
  Direct successor             & If a directed graph contains an edge from $X_i$ to $X_j$ , then we say that $X_j$ is a direct successor of $X_i$. \\
  Ancestors                    & If a directed graph contains a path from $X_i$ to $X_j$ , then we say that $X_i$ is an ancestor of $X_j$. \\
  Descendants                  & If a directed graph contains a path from $X_i$ to $X_j$ , then we say that $X_j$ is a descendant of $X_i$. \\
  $\text{deg}^{\text{out}}(X)$ & The out-degree of $X$ is the number of outgoing edges emanating from that vertex. \\
  Subgraph                     & A subgraph $H$ of a graph $G$ is a graph whose vertices are a subset of the vertex set of $G$, and whose edges are a subset of the edge set of $G$. \\
  Sink vertex                  & A sink vertex is a vertex in a directed graph that has out-degree of zero.\\
  Knot                         & In a directed graph, a knot is a set of vertices with out-edges such that while traversing the directed edges of that directed graph, once a vertex in the knot is reached, you cannot rech any vertex that is not in the knot.\\
\end{tabular}


\subsection{State Digraph}

Presented is a method of detecting when deadlock occurs in an open queueing network $Q$ with $N$ nodes, using a dynamic directed graph, the state graph.

Let the number of servers in node $i$ be denoted by $c_i$.
Define $D(t)=(V(t), E(t))$ as the state graph of $Q$ at time $t$.

The vertices at time \(t\), \(V(t)\) correspond to servers in the
queueing system.
Thus, $\left| V\left(D\left(t\right)\right) \right| = \sum_{i=1}^N c_i$ for all $t \geq 0$.

The edges at time \(t\), \(E(t)\) correspond to a blocking relationship.
There is a directed edge at time \(t\) from vertex \(X_a\in V(t)\) to vertex \(X_b\in
V(t)\) if and only if an individual occupying the server corresponding to vertex
\(X_a\) is being blocked by an individual occupying the server corresponding to
vertex \(X_b\).

The state graph $D(t)$ can be partitioned into $N$ service-station subgraphs,
$D(t)=\bigcup_{i=1}^N d_i(t)$, where the vertices of $d_i(t)$ represent the servers of node $i$.
The vertex set of each subgraph is static over time, however their edge sets may
change.

The state graph is dynamically built up as follows.
When an individual finishes service at node $i$, and this individual's next destination is node $j$, but there is not enough queueing capacity for $j$ to accept that individual, then that individual remains at node $i$ and becomes blocked.
At this point $c_j$ directed edges between this individual's server and the vertices of $d_j(t)$ are created in $D(t)$.

When an individual is released and another customer who wasn't blocked occupies their server, that servers out-edges are removed.
When an individual is released and another customer who was previously blocked occupies their server, that server's out-edges are removed along with the in-edge from the server who that previously blocked customer occupied.
When an individual is released and there isn't another customer to occupy that server, then all edges incident to that server are removed.

This general process of building up the state graph as the queueing network is simulated will now be shown.
Customers are labelled $(i, j, k)$ where $i$ denotes the server that customer is occupying, $j$ denotes that individuals i.d. number, and $k$ denotes the service station that customer is waiting to enter.
As an example, a customer labelled $(A_2, 10, C)$ would have an i.d. number of 2, is occupying server $A_2$ and is currently waiting to join node $C$.
If a customer isn't occupying a server the notation $\emptyset$ is used.
Similarly for customers occupying a server and still in service, their next destination is yet undecided, so $\emptyset$ is used.

The simulation starts with full queues, and every server occupied by a customer in service. This is shown in Figure~\ref{fig:general_buildup_1}.

\begin{figure}[H]
  \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen1_step1} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen1_step1} \\
  \end{tabular}
  \caption{}
  \label{fig:general_buildup_1}
\end{figure}

Customer 13 finishes service, and is blocked from entering node $A$. Figure~\ref{fig:general_buildup_2}.

\begin{figure}[H]
  \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen1_step2} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen1_step2} \\
  \end{tabular}
  \caption{}
  \label{fig:general_buildup_2}
\end{figure}

Then customer 4 finishes service and is blocked from entering node $B$. Figure~\ref{fig:general_buildup_3}.

\begin{figure}[H]
  \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen1_step3} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen1_step3} \\
  \end{tabular}
  \caption{}
  \label{fig:general_buildup_3}
\end{figure}

Then customer 9 finishes service and is blocked from entering node $A$. Figure~\ref{fig:general_buildup_4}.

\begin{figure}[H]
  \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen1_step4} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen1_step4} \\
  \end{tabular}
  \caption{}
  \label{fig:general_buildup_4}
\end{figure}

Finally, in Figure~\ref{fig:general_buildup_5} customer 5 finishes service and wants to reenter the queue for node $A$ but is blocked.
A deadlock situation arises as customer 5 is waiting for customer 4 to move, who is waiting for customer 9 to move, who is waiting for either customer 4 or 5 to move.

\begin{figure}[H]
  \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen1_step5} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen1_step5} \\
  \end{tabular}
  \caption{}
  \label{fig:general_buildup_5}
\end{figure}

The rules on how edges are removed from the state graph will now be shown.
For illustrative purposes the queueing network here is a different queueing network than discussed above.

Here the simulation begins with four customers occupying servers; those at node $A$ blocked to node $B$, the customer at node $C$ blocked to node $A$, and the customer at node $B$ still in service.
This is shown in Figure~\ref{fig:general_builddown_1}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen2_step1} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen2_step1} \\
  \end{tabular}
  \end{center}
  \caption{}
  \label{fig:general_builddown_1}
\end{figure}

Customer 6 finishes service and immediately joins service at node $C$. Figure~\ref{fig:general_builddown_2}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen2_step2} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen2_step2} \\
  \end{tabular}
  \end{center}
  \caption{}
  \label{fig:general_builddown_2}
\end{figure}

Now there is room for customer 4 to move into service at node $B$. Figure~\ref{fig:general_builddown_3}.
Notice that the edge $A_2 \longrightarrow B_1$ remains in the state graph, as customer 5 is still blocked by that server.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen2_step3} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen2_step3} \\
  \end{tabular}
  \end{center}
  \caption{}
  \label{fig:general_builddown_3}
\end{figure}

The customers queueing at node $A$ move along the queue, with customer 3 begining service.
This leaves enough room for customer 7 to join the back of the queue at $A$. Figure~\ref{fig:general_builddown_4}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{ c c c }
      \includestandalone[width=0.62\textwidth]{images/examplenetwork2_scen2_step4} & \hspace{0.1\textwidth} &
      \includestandalone[width=0.2\textwidth]{images/exampledigraph_scen2_step4} \\
  \end{tabular}
  \end{center}
  \caption{}
  \label{fig:general_builddown_4}
\end{figure}

\subsubsection*{Observations}

Consider one weakly connected component $G(t)$ of $D(t)$.
Consider the node $X_a \in G(t)$. If $X_a$ is unoccupied, then $X_a$ has no incident edges.
Consider the case when $X_a$ is occupied by individual $a$, whose next destination is node $j$.
Then $X_a$'s direct successors are the servers occupied by individuals who are blocked or in service at node $j$.
We can interpret all $X_a$'s decendents as the servers whose occupants are directly or indirectly blocking $a$, and we can interpret all $X_a$'s ancestors as those servers whose individuals who are being blocked directly or indirectly by $a$.

Note that the only possibilities for $\text{deg}^{\text{out}}(X_a)$ are being 0 or $c_j$.
If $\text{deg}^{\text{out}}(X_a) = c_j$ then $a$ is blocked by all its direct successors.
The only other situation is that $a$ is not blocked, and $X_a \in G(t)$ because $a$ is in service at $X_a$ and blocking other individuals, in which case $\text{deg}^{\text{out}}(X_a) = 0$.

It is clear that if all of $X_a$'s descendents are occupied by blocked individuals, then the system is deadlocked at time $t$.
We also know that by definition all of $X_a$'s ancestors are occupied by blocked individuals.

Also note that if a service-station subgraph $d_i(t)$ contains edges, then there is an individual in $X_a \in d_i(t)$ that is being blocked by himself.
This does not necassarily mean there is deadlock.


\subsection{Results on the State Digraph}

\begin{theorem}
A deadlocked state arises at time $t$ if and only if $D(t)$ contains a knot.
\end{theorem}

\begin{proof}
Consider one weakly connected component $G(t)$ of $D(t)$ at time $t$.
All vertices of $G(t)$ are either decendents of another vertex and so are occupied by an individual who is blocking someone; or are ancestors of another vertex, and so are occupied by someone who is blocked.

Assume that $G(t)$ contains a vertex $X$ such that $\text{deg}^{\text{out}}(X) = 0$, and there is a path from every other non-sink vertex to $X$.
This imples that $X$'s occupant is not blocked and is a descendent of another vertex.
Therefore $Q$ is not deadlocked as there does not exist a vertex whose descendents are all blocked.

Now assume that we have deadlock.
For a vertex $X$ who is deadlocked, all decendents of $X$ are are occupied by individuals who are blocked, and so must have out-degrees greater than 0.
And so there is no path from $X$ to a vertex with out-degree of 0.
\end{proof}


\begin{lemma}
For a queueing network with two nodes or less, a deadlocked state arises if and only if there exists a weakly connected component without a sink node.
\end{lemma}

\begin{proof}
Consider a one node queueing network $Q_1$.

If there is deadlock, then all servers are occupied by blocked individuals, and so all servers have an out-edge.

Consider a two node queueing network $Q_2$.

If both nodes are involved in the deadlock, so there is a customer in node 1 blocked from entering node 2, and a customer from node 2 blocked from entering node 1, then all servers in node 1 and node 2 in $D(t)$ will have out edges as they are occupied by a blocked individual.
The servers of node 1 and 2 consist of the entirety of $D(t)$, and so there is no sink nodes.

Now consider the case when only one node is involved in the deadlock.
Without loss of generality, let's say that node 1 is in deadlock with itself, then the servers of node 1 have out-edges.
For the servers of node 2 to be part of that weakly conneced component, there either needs to be an edge from a server in node 1 to a server in node 2, or and edge from a server in node 2 to a server in node 1.
An edge from a server in node 1 to a server in node 2 implies that a customer from node 1 is blocked from entering node 2, and so node 1 is not in deadlock with itself.
An edge from a server in node 2 to a server in node 1 implies that a customer in node 2 is blocked from entering node 1.
In this case the server in node 2 has an out-edge, and so there is still no sink.

For the case of a queueing network with more than two nodes, the following counter-example proves the claim:

Begin with all servers occupied by customers in service.
The customer at server $B_1$ is blocked from entering node $A$.
Then the customer at server $C_1$ is blocked from entering node $B$.
Then the customer at server $A_1$ is blocked from entering node $A$.
The resulting state digraph in Figure~\ref{fig:counter_example} has a weakly connected component with a sink.
\end{proof}

\begin{figure}
\begin{center}
\includestandalone[width=0.3\textwidth]{images/counter_example_digraph}
\end{center}
\caption{A Counter-Example State Digraph.}
\label{fig:counter_example}
\end{figure}

\begin{lemma}
An absorbing deadlocked state arises at time $t$ if $D(t)$ doesn't contain a sink vertex.
\end{lemma}

\begin{proof}
A vertex with out-degree greater than zero represents an occupied server whose occupant has finished service and is blocked.
If all vertices have out-degree greater than zero, then all servers are occupied by blocked individuals.
A release at vertex $X_a$ can only be triggered by one of $X_a$'s descendents finishing service.
As all servers are occupied by blocked individuals, no server can finish service, and so no server can release their occupant, implying an absorbing deadlocked state.
\end{proof}

\subsection{Finding Knots}

By definition knots are strongly connected subgraphs where every member's descendants belong to that subgraph.

Using the Python package NetworkX, finding strongly connected components, and finding a vertex's decendants are built-in methods.
The following algoithm, taken from the NetworkX developer zone ticket \#663, is sufficient to identify knots in a directed graph.

\begin{algorithm}[H]
    \DontPrintSemicolon
    Find the strongly connected subgraphs of $D(t)$\;
    \For{strongly connected subgraph $SCS$ in list of strongly connected subgraphs of $D(t)$}{
      \For{vertex $v$ in $SCS$}{
        \If{number of $v$'s decendants $>$ number of vertices in $SCS$}{
          Add $SCS$ to list of knots\;
          break\;
          }\;
        }\;
      }\;
\end{algorithm}



\section{Markov Chain Model}

It is interesting to build an analytical model of the system's behaviour to deadlock.
As a Markov chain model, the deadlocking state is an absorbing state, and so any queueing network that can experience deadlock is guaranteed to experience deadlock.

We can however find the expected time until deadlock is reached.
It is shown in \cite{stewart09} that for a discrete transition matrix of the form $P = \bigl(\begin{smallmatrix} T & U\\ 0 & I \end{smallmatrix} \bigr)$ then the expected number of time steps until absorbtion starting from state $i$ is the $i\text{th}$ element of the vector
\begin{equation}
  (I - T)^{-1}e
\end{equation}
where $e$ is a vector of 1s.
% this.

Another interesting analytical measure to find is the median time to deadlock.

\subsection{One Node Network}\label{sec:1nodenet}
Consider the one node network with feedback loop shown in Figure~\ref{fig:queueingnetwork_1node}.
There is room for $n$ customers to queue at any one time, customers arrive at a rate of $\Lambda$ and served at a rate $\mu$.
Once a customer has finished service he rejoins the queue with probability $r_{11}$, and so exits the system with probability $1 - r_{11}$.

\begin{figure}[H]
  \includestandalone[width=\textwidth]{images/1nodeexample}
  \caption{A one node queueing network.}
  \label{fig:queueingnetwork_1node}
\end{figure}

State space:
        \[S = \{i\in\mathbb{N} \nonscript\; | \nonscript\; 0 \leq i \leq n + 1
        \}\cup\{-1\}\]
where \(i\) denotes number of individuals in service or waiting.

If we define $\delta = i_2 - i_1$ for all $i_k \geq 0$ then the transitions are given by:

\begin{equation}
  q_{i_1, i_2} = \left\{
  \begin{matrix*}[ r ]
    \left. \begin{matrix*}[ r ]
      \Lambda & \text{if } i < n + 1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = 1 \\
    (1 - r_{11})\mu & \text{if } \delta = -1 \\
    0 & \text{otherwise}
  \end{matrix*} \right.
\end{equation}

\begin{equation}
  q_{i, -1} = \left\{
  \begin{matrix*}[ r ]
    r_{11}\mu & \text{if } i = n + 1 \\
    0 & \text{otherwise}
  \end{matrix*}
  \right.
\end{equation}

and

\begin{equation}
  q_{-1, i} = 0
\end{equation}

The Markov chain is shown in Figure~\ref{fig:1nodeMC}.

\begin{figure}[H]
    \includestandalone[width=\textwidth]{images/markov_chain_1node}
    \caption{Markov chain of the one node system.}
    \label{fig:1nodeMC}
\end{figure}

Figure~\ref{fig:timestodeadlock} shows the effect of varying the parameters of the queueing network on times to deadlock.
Base parameters of $\Lambda = 10$, $n = 3$, $\mu = 5$ and $r_{11} = 0.25$ were used.

We can see that increasing the arrival rate $\Lambda$ and the transition probability $r_{11}$ results in reaching deadlock faster.
This is intuitive as increasing these parameters results in the first node's queue filling up quicker.
Increasing the queueing capacity $n$ results in reaching deadlock slower.
Again this are intuitive, as increasing the queueing capacity allows more customers in the system before becoming deadlock.


\begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyL}
  \caption{Varying $\Lambda$}
  \label{fig:timestodeadlock_L}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyr11}
  \caption{Varying $r_{11}$}
  \label{fig:timestodeadlock_r11}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varymu}
  \caption{Varying $\mu$}
  \label{fig:timestodeadlock_mu}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyn}
  \caption{Varying $n$}
  \label{fig:timestodeadlock_n}
\end{subfigure}
\caption{Analytical \& Simulation Results of Times to Deadlock (10,000 iterations)}
\label{fig:timestodeadlock}
\end{figure}

We get interesting behaviour as the service rate $\mu$ varies, as the service rate contributed towards bothmoving customers from the system and allowing customers to rejoin the queue, causing blockages and deadlock.
This behavious can be interperated as follows:
\begin{itemize}
\item At low service rates below a certain threshold, the arrival rate is relatively large compared to the service rate, and we can assume a saturated system.
At this point services where a customer exits the system does not have much of an effect, as we can assume another arrival immediately.
However services where a customer wishes to rejoin the queue results in a blockage as the system is saturated.
Therefore, increasing the service rate here increases the chance of a blockagße, and so the chance of deadlock.
\item Above this threshold the service rate is large enough that we cannot assume a saturated system, and so services where the customer exits the system does have an affect on the number of customers in the system.
Thus increasing the service rate removes people from the system, and as sush there is less chance of getting blocked and deadlocked.
\end{itemize}

This effect is closely related to the transition rate $r_{11}$, as the rate at which the system enters deadlock from a full queue is $r_{11}\mu$.
Figure~\ref{fig:varymuandr} shows the effect of the transition rate on the behaviour of varying the service rate.

\begin{figure}
  \begin{center}
  \includegraphics[width=0.6\textwidth]{images/varymur11}
  \caption{The effect of $r_{11}$ and $\mu$ on times to deadlock.}
  \label{fig:varymuandr}
  \end{center}
\end{figure}

\subsection{Two Node Network without Self Loops}\label{sec:2nodewithoutselfloops}
Consider the queueing network shown in Figure~\ref{fig:queueingnetwork_2nodes}.
This shows two \(M/M/1\) queues, with \(n_i\) queueing capacity at at each service station and service rates $\mu_i$.
$\Lambda_i$ is the external arrival rates to each service station.
All routing possibilities except self loops are possible, where the routing probability from node $i$ to node $j$ is denoted by $r_{ij}$.

\begin{figure}[H]
  \includestandalone[width=\textwidth]{images/2nodeexample}
  \caption{A two node queueing network.}
  \label{fig:queueingnetwork_2nodes}
\end{figure}

\begin{itemize}
    \item State space:
        \[S = \{(i,j)\in\mathbb{N}^{(n_1+2\times n_2+2)} \nonscript\; | \nonscript\; 0 \leq i + j \leq n_1 + n_2 + 2
        \}\cup\{(-1)\}\]

        where \(i\) denotes number of individuals:
            \begin{itemize}
                \item In service or waiting at the first node.
                \item Occupying a server but having finished service at the
                    second node waiting to join the first
            \end{itemize}
        where \(j\) denotes number of individuals:
            \begin{itemize}
                \item In service or waiting at the second node.
                \item Occupying a server but having finished service at the
                    first node waiting to join the first
            \end{itemize}
        and the state $(-1)$ denotes the deadlocked state.
\end{itemize}

If we define $\delta = (i_2, j_2) - (i_1, j_1)$ for all $(i_k, j_k) \in S$, then the transitions are given by:

\begin{equation}
  q_{(i_1, j_1),(i_2, j_2)} = \left\{
  \begin{matrix*}[ r ]
    \left. \begin{matrix*}[ r ]
      \Lambda_1 & \text{if } i_1 < n_1 + 1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (1, 0) \\
    \left. \begin{matrix*}[ r ]
      \Lambda_2 & \text{if } j_1 < n_2 + 1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (0, 1) \\
    \left. \begin{matrix*}[ r ]
      (1 - r_{12})\mu_1 & \text{if } j_1 < n_1 + 2 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (-1, 0) \\
    \left. \begin{matrix*}[ r ]
      (1 - r_{21})\mu_2 & \text{if } i_1 < n_1 + 2 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (0, -1) \\
    \left. \begin{matrix*}[ r ]
      r_{12}\mu_1 & \text{if } j_1 < n_2 + 2 \text{ and } (i_1, j_1) \neq (n_1 + 2, n_2) \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (-1, 1) \\
    \left. \begin{matrix*}[ r ]
      r_{21}\mu_2 & \text{if } i_1 < n_1 + 2 \text{ and } (i_1, j_1) \neq (n_1, n_2 + 2) \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (1, -1) \\
    0 & \text{otherwise}
  \end{matrix*} \right.
\end{equation}

\begin{equation}
  q_{(i_1, j_1), (-1)} = \left\{
  \begin{matrix*}[ r ]
    r_{21}\mu_2 & \text{if } (i, j) = (n_1, n_2 + 2) \\
    r_{12}\mu_1 & \text{if } (i, j) = (n_1 + 2, n_2) \\
    0 & \text{otherwise}
  \end{matrix*}
  \right.
\end{equation}

and

\begin{equation}
  q_{-1, s} = 0
\end{equation}

For $n_1 = 1$ and $n_2 = 2$, the resulting Markov chain is shown in Figure~\ref{fig:2nodeMC}.

\begin{figure}[H]
    \includestandalone[width=\textwidth]{images/markov_chain}
    \caption{Markov chain of the two node system without self loops, $n_1=1$ and $n_2=2$.}
    \label{fig:2nodeMC}
\end{figure}

Figure~\ref{fig:timestodeadlock2} shows the effect of varying the parameters of the above Markov model.
Base parameters of $\Lambda_1 = 4$, $\Lambda_2 = 5$, $n_1 = 3$, $n_2 = 2$, $\mu_1 = 10$, $\mu_2 = 8$, $r_{12} = 0.25$ and $r_{21} = 0.15$ were used.
Only parameters for one node are shown, as the other node's parameters will have the same affect.
We can see that we get similar behaviour as the 1 node network.

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyL1}
  \caption{Varying $\Lambda_1$}
  \label{fig:timestodeadlock2_L1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyr12}
  \caption{Varying $r_{12}$}
  \label{fig:timestodeadlock2_r12}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varymu1}
  \caption{Varying $\mu_1$}
  \label{fig:timestodeadlock2_mu1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/varyn1}
  \caption{Varying $n_1$}
  \label{fig:timestodeadlock2_n1}
\end{subfigure}
\caption{Analytical \& Simulation Results of Times to Deadlock (10,000 iterations)}
\label{fig:timestodeadlock2}
\end{figure}


\subsection{Two Node Network each with Self Loops}\label{sec:2nodeselfloops}
Consider the queueing network shown in Figure~\ref{fig:queueingnetwork_2nodesfeedback}.
This shows two \(M/M/1\) queues, with \(n_i\) queueing capacity at at each service station and service rates $\mu_i$.
$\Lambda_i$ is the external arrival rates to each service station.
All routing possibilities are possible, where the routing probability from node $i$ to node $j$ is denoted by $r_{ij}$.

\begin{figure}[H]
  \includestandalone[width=\textwidth]{images/2nodefeedbackexample}
  \caption{A two node queueing network, each with feedback loops.}
  \label{fig:queueingnetwork_2nodesfeedback}
\end{figure}

\begin{itemize}
    \item State space:
        \[S = \{(i,j)\in\mathbb{N}^{(n_1+2\times n_2+2)} \nonscript\; | \nonscript\; 0 \leq i + j \leq n_1 + n_2 + 2
        \}\cup\{(-1), (-2), (-3)\}\]

        where \(i\) denotes number of individuals:
            \begin{itemize}
                \item In service or waiting at the first node.
                \item Occupying a server but having finished service at the
                    second node waiting to join the first
            \end{itemize}
        where \(j\) denotes number of individuals:
            \begin{itemize}
                \item In service or waiting at the second node.
                \item Occupying a server but having finished service at the
                    first node waiting to join the first
            \end{itemize}
        and the state $(-3)$ denotes the deadlocked state cause by both nodes; $(-1)$ denotes the deadlocked state caused by the first node only; and $(-2)$ denotes the deadlocked state caused by the second node only.
\end{itemize}

If we define $\delta = (i_2, j_2) - (i_1, j_1)$ for all $(i_k, j_k) \in S$, then the transitions are given by:

\begin{equation}
  q_{(i_1, j_1),(i_2, j_2)} = \left\{
  \begin{matrix*}[ r ]
    \left. \begin{matrix*}[ r ]
      \Lambda_1 & \text{if } i_1 < n_1 + 1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (1, 0) \\
    \left. \begin{matrix*}[ r ]
      \Lambda_2 & \text{if } j_1 < n_2 + 1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (0, 1) \\
    \left. \begin{matrix*}[ r ]
      (1 - r_{11} - r_{12})\mu_1 & \text{if } j_1 < n_1 + 2 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (-1, 0) \\
    \left. \begin{matrix*}[ r ]
      (1 - r_{21} - r_{22})\mu_2 & \text{if } i_1 < n_1 + 2 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (0, -1) \\
    \left. \begin{matrix*}[ r ]
      r_{12}\mu_1 & \text{if } j_1 < n_2 + 2 \text{ and } (i_1, j_1) \neq (n_1 + 2, n_2) \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (-1, 1) \\
    \left. \begin{matrix*}[ r ]
      r_{21}\mu_2 & \text{if } i_1 < n_1 + 2 \text{ and } (i_1, j_1) \neq (n_1, n_2 + 2) \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } \delta = (1, -1) \\
    0 & \text{otherwise}
  \end{matrix*} \right.
\end{equation}

\begin{equation}\label{equ:todeadlock2}
  q_{(i_1, j_1), (-1)} = \left\{
  \begin{matrix*}[ r ]
    r_{11}\mu_1 & \text{if } i > n_1 \text{ and } j < n_2 + 2 \\
    0 & \text{otherwise}
  \end{matrix*}
  \right.
\end{equation}

\begin{equation}\label{equ:todeadlock3}
  q_{(i_1, j_1), (-2)} = \left\{
  \begin{matrix*}[ r ]
    r_{22}\mu_2 & \text{if } j > n_2 \text{ and } i < n_1 + 2 \\
    0 & \text{otherwise}
  \end{matrix*}
  \right.
\end{equation}

\begin{equation}
  q_{(i_1, j_1), (-3)} = \left\{
  \begin{matrix*}[ r ]
    r_{21}\mu_2 & \text{if } (i, j) = (n_1, n_2 + 2) \\
    r_{12}\mu_1 & \text{if } (i, j) = (n_1 + 2, n_2) \\
    0 & \text{otherwise}
  \end{matrix*}
  \right.
\end{equation}

and

\begin{align}
  q_{-1, s} = 0 \\
  q_{-2, s} = 0 \\
  q_{-3, s} = 0
\end{align}

Note that the there are only two differences between this formulation and the formulation given in Subsection~\ref{sec:2nodewithoutselfloops}: the probabilities of leaving nodes 1 and 2 are now $(1-r_{11}-r{12})\mu_1$ and $(1-r_{21}-r_{22})\mu_2$; and there are now two more ways to reach deadlock, Equation~\ref{equ:todeadlock2} and Equation~\ref{equ:todeadlock3}.

For $n_1 = 1$ and $n_2 = 2$, the resulting Markov chain is shown in Figure~\ref{fig:2nodeMCfeedback}.

\begin{figure}[H]
    \includestandalone[width=\textwidth]{images/markov_chain_feedback}
    \caption{Markov chain of the two node system with self loops, $n_1=1$ and $n_2=2$.}
    \label{fig:2nodeMCfeedback}
\end{figure}

Figure~\ref{fig:timestodeadlockfeedback} shows the effect of varying the parameters of the above Markov model.
Base parameters of $\Lambda_1 = 4$, $\Lambda_2 = 5$, $n_1 = 3$, $n_2 = 2$, $\mu_1 = 10$, $\mu_2 = 8$, $r_{11} = 0.1$, $r_{12} = 0.25$, $r_{21} = 0.15$ and $r_{22} = 0.1$ were used.


\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_L1fb}
  \caption{Varying $\Lambda_1$}
  \label{fig:timestodeadlockfb_L1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_L2fb}
  \caption{Varying $\Lambda_2$}
  \label{fig:timestodeadlockfb_L2}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_mu1fb}
  \caption{Varying $\mu_1$}
  \label{fig:timestodeadlockfb_mu1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_mu2fb}
  \caption{Varying $\mu_2$}
  \label{fig:timestodeadlockfb_mu2}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_n1fb}
  \caption{Varying $n_1$}
  \label{fig:timestodeadlockfb_n1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/vary_n2fb}
  \caption{Varying $n_2$}
  \label{fig:timestodeadlockfb_n2}
\end{subfigure}
\caption{Analytical \& Simulation Results of Times to Deadlock (10,000 iterations)}
\label{fig:timestodeadlockfeedback}
\end{figure}

Figure~\ref{fig:timestodeadlockfb_n1} shows interesting behaviour.
Increasing $n_1$ causes a longer time to deadlock up to a point, where increasing $n_1$ any more does not affect the time to deadlock.
This is due to the fact that there are other ways to get to deadlock, and we are only interested in the first instance of any of these deadlocks.
Getting to deadlocked state (-2) is not affected by $n_1$, and so once $n_1$ goes over a certain threshold the system always reaches (-2) before any other deadlocked state, and so the time to deadlock is unaffected by increasing $n_1$ any further.

This behaviour will be exhibited while $n_2$ increases too, however the threshold will take longer to reach as the base parameter for $n_1$ is larger than the base parameter for $n_2$.

This behaviour is highlighted in the heatmap shown in Figure~\ref{fig:capacitiesheatmap}, where the analytical mean time to deadlock is shown with combinations of $n_1$ and $n_2$.
For each value of $n_2$, once a certain threshold of $n_1$ is reached no more change in time to deadlock occurs.
Similarly for each value of $n_1$, once a certain threshold o $n_2$ is reached no more change in time to deadlock occurs.
The behaviour is unsymmetrical due to the other parameters associated with Node 1 and Node 2 being unsymmetrical.

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.5\textwidth]{images/n1n2_heatmap}
  \caption{Deadlocking behaviour, varying $n_1$ and $n_2$}
  \label{fig:capacitiesheatmap}
  \end{center}
\end{figure}

The heatmaps in Figure~\ref{fig:heatmaps} illustrate how varying the two transition probabilities out of each node affects the time to deadlock.
Note the shape of the heatmap, this is due to the restriction than $r_{11} + r{12} \leq 1$ and $r_{21} + r_{22} \leq 1$.
We can see for both nodes it is the rejoining probability ($r_{11}$ and $r_{22}$) that has the most drastic effect on time to deadlock.
This effect is greater for Node 2, the node that has the smaller queueing capacity.

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/N1_heatmap}
  \caption{Analytical: Varying transition probabilities at Node 1}
  \label{fig:heatmap_anal_1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/N2_heatmap}
  \caption{Analytical: Varying transition probabilities at Node 2}
  \label{fig:heatmap_anal_2}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/N1_heatmap_sim}
  \caption{Simulation: Varying transition probabilities at Node 1}
  \label{fig:heatmap_sim_1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/N2_heatmap_sim}
  \caption{Simulation: Varying transition probabilities at Node 2}
  \label{fig:heatmap_sim_2}
\end{subfigure}
\caption{Analytical \& Simulation Results of Times to Deadlock, varying Transition Probabilities (10,000 iterations)}
\label{fig:heatmaps}
\end{figure}

Times to deadlock in this case means the time to the first instance of deadlock.
There is however three different deadlocked states which the queueing network can fall into, -1, -2 and -3.

A method is shown in \cite{stewart09} to find the probabilities of which absorbing state a Markov chain will reach.
The discrete transition matrix must be in the form $P = \bigl(\begin{smallmatrix} T & U\\ 0 & I \end{smallmatrix} \bigr)$.
Then $A = (I - T)^{-1}U$, and the $(i, j)^{\text{th}}$ element of $A$ corresponds to the probability of reaching absorbing state $j$ from transient state $i$.

Figure~\ref{fig:absorbingprobs} shows how varying the parameters of the queueing network affects the absorption probabilities.

\begin{figure}[H]
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobL1}
  \caption{Varying $\Lambda_1$}
  \label{fig:absprobL1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobL2}
  \caption{Varying $\Lambda_2$}
  \label{fig:absprobL2}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobmu1}
  \caption{Varying $\mu_1$}
  \label{fig:absprobmu1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobmu2}
  \caption{Varying $\mu_2$}
  \label{fig:absprobmu2}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobn1}
  \caption{Varying $n_1$}
  \label{fig:absprobn1}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
  \includegraphics[width=\textwidth]{images/absprobn2}
  \caption{Varying $n_2$}
  \label{fig:absprobn2}
\end{subfigure}
\caption{Probabilities of reaching each deadlocked state.}
\label{fig:absorbingprobs}
\end{figure}


\subsection{One Node Network, Multi-Server}
Consider the one node network with feedback loop discussed in Subsection~\ref{sec:1nodenet}, now with $c$ parallel servers.

State space:
        \[S = \{i\in\mathbb{N} \nonscript\; | \nonscript\; 0 \leq i \leq n + 2c\}\]
where \(i\) denotes number of individuals at the node plus the number of individuals blocked at that node.
For example, $i=n+c+2$ denotes a full system, $n+c$ individuals in the node, and 2 of those individuals are also blocked.
The state $i=n+2c$ denotes the deadlocked state.

If we define $\delta = i_2 - i_1$ for all $i_k \geq 0$, then the transitions are given by:

\begin{equation}
  q_{i_1, i_2} = \left\{
  \begin{matrix*}[ r ]
    \left. \begin{matrix*}[ r ]
      \Lambda & \text{if } \delta = 1 \\
      (1-r_{11})\mu\text{min}(i, c) & \text{if } \delta = -1 \\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } i_1 < n + c \\
  \end{matrix*} \right.
\end{equation}

\begin{equation}
  q_{i_1, i_2} = \left\{
  \begin{matrix*}[ r ]
    \left. \begin{matrix*}[ r ]
      (c-k)r_{11}\mu & \text{if } \delta = 1 \\
      (1-r_{11})(c-k)\mu & \text{if } \delta = -j-1\\
      0 & \text{otherwise}
    \end{matrix*} \right\} & \text{if } i_1 = n + c + j \\
  \end{matrix*} \right.
  \quad \forall \quad 0 \leq j \leq c
\end{equation}

Increasing the amount of servers has a similar effect to increasing the queueing capacity, there are now more transient spaces to go through before reaching the deadlocked state.
Varying the amount of servers has a greater effect on the time to deadlock however, as any states in which customers are blocked ($i=n+c+1$ to $i=n+2c$) can jump back to state $i=n+c-1$ simply with a service and an exit.
Increasing the amount of servers also increases the rate at which $i$ are reduced for most states, but not the rates at which $i$ is increased.

Figure~\ref{fig:timestodeadlock1nodemultiserver} shows the effect of varying the parameters of the above Markov model.
Base parameters of $\Lambda = 6$, $n = 3$, $\mu = 2$ and $r_{11} = 0.5$ were used.

\begin{figure}
  \begin{center}
  \includegraphics[width=0.6\textwidth]{images/vary_c_1Nms}
  \caption{The effect of $c$ on times to deadlock.}
  \label{fig:timestodeadlock1nodemultiserver}
  \end{center}
\end{figure}


% \subsection{A Bound on the Mean Time to Deadlock}
% In this section we shall define four deadlocking queueing networks as follows:

% \begin{itemize}
%   \item Define $\Omega_{1_1}$ as the 1 node queueing network described in Subsection~\ref{sec:1nodenet} with the parameter set $\{\Lambda_1$, $\mu_1$, $n_1$, $r_{11}\}$. Let its mean time to deadlock be denoted by $\omega_{1_1}$.
%   \item Define $\Omega_{1_2}$ as the 1 node queueing network described in Subsection~\ref{sec:1nodenet} with the parameter set $\{\Lambda_2$, $\mu_2$, $n_2$, $r_{22}\}$. Let its mean time to deadlock be denoted by $\omega_{1_2}$.
%   \item Define $\Omega_2$ as the 2 node queueing network described in Subsection~\ref{sec:2nodewithoutselfloops} with the parameter set $\{\Lambda_1$, $\Lambda_2$, $\mu_1$, $\mu_2$, $n_1$, $n_2$, $r_{12}$, $r_{21}\}$. Let its mean time to deadlock be denoted by $\omega_2$.
%   \item Define $\Omega$ as the 2 node queueing network described in Subsection~\ref{sec:2nodeselfloops} with the parameter set $\{\Lambda_1$, $\Lambda_2$, $\mu_1$, $\mu_2$, $n_1$, $n_2$, $r_{11}$, $r_{12}$, $r_{21}$, $r_{22}\}$. Let its mean time to deadlock be denoted by $\omega$.
% \end{itemize}

% Figure~\ref{fig:decomposeqnet} shows how $\Omega$ contains, and is made up by, $\Omega_{1_1}$, $\Omega_{1_2}$ and $\Omega_2$.

% \begin{figure}[H]
% \begin{subfigure}[b]{0.5\textwidth}
%   \includestandalone[width=\textwidth]{images/omega11}
%   \caption{$\Omega_{1_1}$ within $\Omega$}
%   \label{fig:omega11withinomega}
% \end{subfigure}
% \begin{subfigure}[b]{0.5\textwidth}
%   \includestandalone[width=\textwidth]{images/omega12}
%   \caption{$\Omega_{1_2}$ within $\Omega$}
%   \label{fig:omega12withinomega}
% \end{subfigure}
% \begin{center}
% \begin{subfigure}[b]{0.5\textwidth}
%   \includestandalone[width=\textwidth]{images/omega2}
%   \caption{$\Omega_2$ within $\Omega$}
%   \label{fig:omega2withinomega}
% \end{subfigure}
% \end{center}
% \caption{Decomposition of $\Omega$ into $\Omega_{1_1}$, $\Omega_{1_2}$ and $\Omega_2$}
% \label{fig:decomposeqnet}
% \end{figure}

% \begin{theorem}
% For any parameter sets the following inequality holds:
% $\omega \leq \min(\omega_{1_1}, \omega_{1_2}, \omega_2)$
% \end{theorem}

% \begin{proof}
% First, define some systems:
% \begin{itemize}
%   \item Let $\widetilde{\Omega}_{1_1}$ denote the $\Omega_{1_1}$ sytem within $\Omega$. Let $\widetilde{\omega}_{1_1}$ denote the mean time to deadlock of $\widetilde{\Omega}_{1_1}$.
%   \item Let $\widetilde{\Omega}_{1_2}$ denote the $\Omega_{1_1}$ sytem within $\Omega$. Let $\widetilde{\omega}_{1_2}$ denote the mean time to deadlock of $\widetilde{\Omega}_{1_2}$.
%   \item Let $\widetilde{\Omega}_2$ denote the $\Omega_{1_1}$ sytem within $\Omega$. Let $\widetilde{\omega}_2$ denote the mean time to deadlock of $\widetilde{\Omega}_2$.
% \end{itemize}

% Now $\widetilde{\omega}_{1_1}$ is the mean time to state (-1) in $\Omega$, $\widetilde{\omega}_{1_2}$ is the mean time to state (-2) in $\Omega$ and $\widetilde{\omega}_2$ is the mean time to state (-3) in $\Omega$.
% Therefore $\omega = \min(\widetilde{\omega}_{1_1}, \widetilde{\omega}_{1_2}, \widetilde{\omega}_2)$, as the mean time to deadlock in $\Omega$ is the expected time it takes to reach either (-1), (-2) or (-3), whichever comes first.

% Comparing $\widetilde{\Omega}_{1_1}$ to $\Omega_{1_1}$:
% The effective arrival rate in $\widetilde{\Omega}_{1_1}$ is greater than or equal to the effective arrival rate in $\Omega_{1_1}$; this is due to the extra customers who have transitioned from the Node 2 to Node 1.
% As an increase in the arrival rate causes the mean time to deadlock to decrease, we can conclude $\widetilde{\omega}_{1_1} \leq \omega_{1_1}$.

% Similarly we can conclude $\widetilde{\omega}_{1_2} \leq \omega_{1_2}$.

% Comparing $\widetilde{\Omega}_2$ to $\Omega_2$:
% The effective arrival rate to Node 1 in $\widetilde{\Omega}_2$ is greater than or equal to the effective arrival rate to Node 1 in $\Omega_2$.
% This is due to the extra customers who are rejoining the queue after service.
% Similarly the effective arrival rate to Node 2 in $\widetilde{\Omega}_2$ is greater than or equal to the effective arrival rate to Node 2 in $\Omega_2$.
% Therefore $\widetilde{\omega}_2 \leq \omega_2$

% And so

% \begin{align*}
% \min(\widetilde{\omega}_{1_1}, \widetilde{\omega}_{1_2}, \widetilde{\omega}_2) &\leq \min(\omega_{1_1}, \omega_{1_2}, \omega_2) \\
% \omega &\leq \min(\omega_{1_1}, \omega_{1_2}, \omega_2)
% \end{align*}

% \end{proof}


\section{Resolving Deadlock}
Once the system falls into a deadlocked state for the first time, that is the first transient deadlocked state since the last resolution, the simulated needs to automatically resolve the deadlock and allow services to resume again.
This is not necassarily as simple as moving a blocked customer to his next node, as we need to conserve the numbers of customers at each service station.
Closer inspection of the state digraph is required in order to find a way to resolve deadlock whilst conserving this property.

At deadlock, the service stations can be classified into the following three mutually exclusive categories:
\begin{itemize}
    \item Nodes that are not deadlocked: These are nodes that do not contain any blocked individuals.
    \item Causation nodes, nodes causing deadlock: These are nodes where every server is occupied by a blocked individual, and there is at least one blocked individual waiting to enter that node who is directly or indirectly being blocked by an individual in this node.
    \item Affected nodes, nodes affected by deadlock: These are nodes containing at least one blocked individual who is directly or indirectly being blocked by an individual at a node that is causing deadlock, but is not classified as causing deadlock itself.
\end{itemize}

At the first instance of deadlock, there will only be one knot in $D(t)$.
Let us denote the knot as $K$.
The vertices of $K$ correspond to servers.
As there is no sink node, all vertices of $K$ have an out-edge, and so all vertices in $K$ contain a blocked individual.
Therefore, there are no vertices in $K$ belonging to nodes that are not deadlocked.
All vertices of $K$ correspond to servers of causation nodes, and a causation node has all its servers belonging to $K$.
An affected node has servers belonging to the same weakly connected component as $K$, but does ot have servers in $K$.

When choosing which customer to move in order to resolve deadlock, we must be careful to conserve the number of customers at each service station.
Causation nodes have full queues, and a customer may only be moved into a full queue if this causes another customer to simultaneously move from this node.
Another complication arises due to the blocking mechanism used, in which those customers who have been blocked longer must be moved first.
This property may have to be broken in order to ensure the conservation property is not.
Assume that we have weighted the edges of the digraph with the time that they were created. % If this works then I'll include this in the write up of how state digraph is formed

The following algorithm is proposed in order to resolve deadlock:

\begin{algorithm}[H]
    \DontPrintSemicolon
    Find the knot $K$ in $D(t)$\;
    Find the cycle $C \in K$ whose average edge weight is minimum\;
    Start at $V_0$\;
    \For{$V_i$ in $C$}{
    Move the individual who is waiting to get to $V_{i+1}$\;}
    Redraw $D(t)$\;
\end{algorithm}



\bibliographystyle{plain}
\bibliography{refs}





\end{document}
